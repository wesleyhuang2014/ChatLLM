#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : AI.  @by PyCharm
# @File         : chatpdf
# @Time         : 2023/4/25 17:01
# @Author       : betterme
# @WeChat       : meutils
# @Software     : PyCharm
# @Description  :

import streamlit as st
from meutils.pipe import *
from meutils.serving.st_utils import display_pdf, st_chat, set_config

from chatllm.applications.chatpdf import ChatPDF

st.set_page_config(page_title='ğŸ”¥ChatPDF', layout='wide', initial_sidebar_state='collapsed')


################################################################################################################
class Conf(BaseConfig):
    encode_model = 'nghuyong/ernie-3.0-nano-zh'
    llm = "THUDM/chatglm-6b"  # /Users/betterme/PycharmProjects/AI/CHAT_MODEL/chatglm
    cachedir = 'pdf_cache'

    topk: int = 3
    threshold: float = 0.66


conf = Conf()
conf = set_config(conf)


# st.json(conf.dict())


################################################################################################################


@st.cache_resource()
def qa4pdf(encode_model, model_name_or_path):
    qa = ChatPDF(encode_model=encode_model)
    qa.load_llm4chat(model_name_or_path=model_name_or_path)
    return qa


################################################################################################################

tabs = st.tabs(['ChatPDF', 'PDFæ–‡ä»¶é¢„è§ˆ'])

file = st.sidebar.file_uploader("ä¸Šä¼ PDF", type=['pdf'])
bytes_array = ''
if file:
    bytes_array = file.read()
    base64_pdf = base64.b64encode(bytes_array).decode('utf-8')

    with tabs[1]:
        if bytes_array:
            display_pdf(base64_pdf)
        else:
            st.warning('### è¯·å…ˆä¸Šä¼ PDF')
################################################################################################################
try:
    qa = qa4pdf(conf.encode_model, conf.llm)
    with st.spinner("æ„å»ºçŸ¥è¯†åº“ï¼šæ–‡æœ¬å‘é‡åŒ–"):
        disk_cache(location=conf.cachedir)(qa.create_index)(bytes_array)
except Exception as e:
    st.warning('å¯åŠ¨å‰é€‰æ‹©æ­£ç¡®çš„å‚æ•°è¿›è¡Œåˆå§‹åŒ–')
    st.error(e)


################################################################################################################
def reply_func(query):
    for response, _ in qa(query=query, topk=conf.topk, threshold=conf.threshold):
        yield response


with tabs[0]:
    if file:
        container = st.container()  # å ä½ç¬¦
        text = st.text_area(label="ç”¨æˆ·è¾“å…¥", height=100, placeholder="è¯·åœ¨è¿™å„¿è¾“å…¥æ‚¨çš„é—®é¢˜")

        if st.button("å‘é€", key="predict"):
            with st.spinner("ğŸ¤” AI æ­£åœ¨æ€è€ƒï¼Œè¯·ç¨ç­‰..."):
                history = st.session_state.get('state')
                st.session_state["state"] = st_chat(
                    text, history, container=container,
                    previous_messages=['è¯·ä¸Šä¼ éœ€è¦åˆ†æçš„PDFï¼Œæˆ‘å°†ä¸ºä½ è§£ç­”'],
                    reply_func=reply_func,
                )

        with st.expander('ç‚¹å‡»å¯æŸ¥çœ‹è¢«å¬å›çš„çŸ¥è¯†'):
            st.dataframe(qa.recall)
